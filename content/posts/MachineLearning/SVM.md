---
title: Support Vector Machine
toc: true
authors:
  - EndlessPeak
tags:
  - SVM
  - Machine Learning
categories: 
  - Machine Learning
date: 2021-04-17 23:00:00
hidden: true
draft: true
---

支持向量机，英文名为support vector machine，简称SVM，它是一种传统的机器学习方法，在神经网络出现之前是效果最好的分类模型，修改后的SVM也可以运行回归任务。通常情况下，支持向量机是一种二分类模型，其基本模型定义为特征空间上的间隔最大的线性分类器，间隔最大使得它有别于感知机。支持向量机的学习策略是间隔最大化，可形式化为一个凸二次规划问题的求解，或等价于正则化的合页损失函数最小化的问题。支持向量机的学习算法是求解凸二次规划的最优化算法。

<!--more-->

## 引入

### 感知机

理解支持向量机应该从感知机（亦即线性分类器）开始。感知机是二类分类的线性分类模型。

给定一些数据点，它们分别属于两个不同的类，现在要找到一个线性分类器把这些数据分成两类。如果用x表示数据点，用y表示类别（y可以取1或者-1，分别代表两个不同的类），一个线性分类器的学习目标便是要在n维的数据空间中找到一个将实例划分为正负两类的分离**超平面**（hyper plane）。

输入为m个实例的n维特征向量，则第i个数据 $ x_i= \lbrace x_{i1},x_{i2},...,x_{in} \rbrace $，输出为各实例的类别，$y_i=\lbrace +1,-1 \rbrace$。

>如何理解超平面：在二维的情况下，假设正负两类线性可分，则划分正负两类的方法为在坐标轴中找到一条直线，将正负两类分开。三维的情况下，假设正负两类平面可分，则划分的方法是找到一个平面，将正负两类分开。三维以上的情况类似。划分正负类的线/面/几何体被称为超平面。

>注1：x是n维列向量，在n维欧式空间中的数据点用$x$表示，而不是用$\lbrace x,y \rbrace$表示。
>注2：$n$维欧式空间中划分正负类的超平面是$n-1$维。

这个超平面的方程表示为（T代表转置）：

$$
w^Tx+b=0
$$
其中，$w \in R^n$被定义为权重向量,可认为是列向量,$b \in R$被定义为偏置。

若设$g(x)=w^Tx+b$，则由输入空间到输出空间的如下的函数方程表示定义为感知机：
$$
f(x)=sign(g(x))=sign(w^Tx+b)
$$

### 超平面

考虑有关超平面的第一个问题：$w$的方向如何？

若设$x_1,x_2$是超平面上的任意两点，则有：
$$
w^Tx_1+b=w^Tx_2+b
$$
$$
w^T(x_1-x_2)=0
$$
即$w$方向与超平面垂直。

考虑有关超平面的第二个问题：
